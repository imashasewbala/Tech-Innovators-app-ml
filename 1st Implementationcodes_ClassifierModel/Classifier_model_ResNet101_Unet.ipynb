{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d86dab",
   "metadata": {},
   "source": [
    "Used Dummy Unet Model for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6351de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained U-Net model\n",
    "segmentation_model = load_model('unet_model.h5')\n",
    "\n",
    "def segment_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (256, 256))  # Resize to match the model's input size\n",
    "    img = img / 255.0  # Normalize the image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    segmented_img = segmentation_model.predict(img)\n",
    "    segmented_img = np.squeeze(segmented_img, axis=0)  # Remove batch dimension\n",
    "    segmented_img = (segmented_img > 0.5).astype(np.uint8)  # Threshold the output\n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd5111",
   "metadata": {},
   "source": [
    "Example Usage: It serves as a quick example or test case to show how to apply the function segment_and_extract to an individual image. Functionality Test: It verifies that the segment_and_extract function works correctly by running it on a sample image and obtaining the extracted features. Feature Extraction: It extracts the features from the provided image using the segmentation model (a placeholder in the current code) and the feature extraction model (ResNet101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Load the pre-trained ResNet101 model without the top fully connected layers\n",
    "base_model = ResNet101(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img = cv2.resize(image, (224, 224))  # Resize to match ResNet input size\n",
    "    if img.shape[-1] == 1:  # Convert grayscale to RGB if needed\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    img = preprocess_input(img)  # Preprocess for ResNet\n",
    "    return img\n",
    "\n",
    "def extract_features(image, model):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    features = model.predict(preprocessed_image)\n",
    "    return features\n",
    "\n",
    "def segment_image(image_path):\n",
    "    # Dummy function for image segmentation, replace with actual segmentation code\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def segment_and_extract(image_path):\n",
    "    segmented_img = segment_image(image_path)\n",
    "    features = extract_features(segmented_img, base_model)\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "image_path = 'C:/Users/User/Desktop/back up/my doc/RESEARCH/CINNAMON CODES/test.jpeg'\n",
    "features = segment_and_extract(image_path)\n",
    "\n",
    "dataset_dir = r'C:\\Users\\User\\Desktop\\back up\\my doc\\RESEARCH\\CINNAMON CODES\\Dataset'\n",
    "classes = [class_name for class_name in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, class_name))]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Initialize Label Binarizer for one-hot encoding the labels\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(classes)\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        segmented_img = segment_image(image_path)\n",
    "        features = extract_features(segmented_img, base_model)\n",
    "        X.append(features[0])  # Extracted features are 2D, take the first dimension\n",
    "        y.append(class_name)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = lb.transform(y)\n",
    "\n",
    "# Optionally, save the extracted features and labels for future use\n",
    "np.save('X_features.npy', X)\n",
    "np.save('y_labels.npy', y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "\n",
    "\n",
    "# Define your classifier\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(2048,)),  # Assuming ResNet101 output features of size 2048\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes should be the number of classes you have\n",
    "])\n",
    "# Define your learning rate\n",
    "learning_rate = 0.0001  # Adjust this value as needed\n",
    "\n",
    "# Instantiate the Adam optimizer with the desired learning rate\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier model\n",
    "model.save('classifier_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of a new image\n",
    "def predict_image_class(image_path, segmentation_model, feature_extraction_model, classifier_model):\n",
    "    segmented_img = segment_image(image_path)\n",
    "    features = extract_features(segmented_img, feature_extraction_model)\n",
    "    prediction = classifier_model.predict(features)\n",
    "    predicted_class = lb.inverse_transform(prediction)[0]\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage for prediction\n",
    "new_image_path = 'C:/Users/User/Desktop/back up/my doc/RESEARCH/CINNAMON CODES/test_image.jpg'\n",
    "classifier_model = load_model('classifier_model.h5')\n",
    "predicted_class = predict_image_class(new_image_path, segmentation_model, base_model, classifier_model)\n",
    "print(f\"The predicted class is: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044955d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of a new image\n",
    "def predict_image_class(image_path, segmentation_model, feature_extraction_model, classifier_model):\n",
    "    segmented_img = segment_image(image_path)\n",
    "    features = extract_features(segmented_img, feature_extraction_model)\n",
    "    prediction = classifier_model.predict(features)\n",
    "    predicted_class = lb.inverse_transform(prediction)[0]\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage for prediction\n",
    "new_image_path = 'C:/Users/User/Desktop/back up/my doc/RESEARCH/CINNAMON CODES/uploads/WhatsApp Image 2024-06-25 at 17.37.43.jpeg'\n",
    "classifier_model = load_model('classifier_model.h5')\n",
    "predicted_class = predict_image_class(new_image_path, segmentation_model, base_model, classifier_model)\n",
    "print(f\"The predicted class is: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
